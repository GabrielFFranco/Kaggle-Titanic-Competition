{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Deducing Age and Survival change using Keras Neural Network**\nIn this notebook I'll create a code to predict if a Titanic passenger would survive it's disaster. The data used in the model contains information about the passengers from titanic (see data dictionary below). One major factor about this code is that I try to predict the passenger's age using two methods: Method 1: Filling the missing ages by hand using the method created by [ALLOHVK](https://www.kaggle.com/allohvk). Method 2: Using a Deep Neural Network model. \n\n**Data Directory:**\n\n* Variable (Meaning)\n* Survival (If passenger survived): 0 = No, 1 = Yes\n* Pclass (Ticket class): 1 = 1st, 2 = 2nd, 3 = 3rd\n* Sex (Passenger's Sex)\n* Age (Paseenger's age in years)\n* Sibsp (Number of passenger's siblings/spouses aboard the Titanic)\n* Parch (Number of passenger's parents/children aboard the Titanic)\n* Ticket (Ticket number)\n* Fare (Passenger fare)\n* Cabin (Cabin number)\n* Embarked (Port of Embarkation): C = Cherbourg, Q = Queenstown, S = Southampton","metadata":{}},{"cell_type":"code","source":"# Necessary libraries for the code\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-07T18:14:52.757449Z","iopub.execute_input":"2022-12-07T18:14:52.757844Z","iopub.status.idle":"2022-12-07T18:14:52.768727Z","shell.execute_reply.started":"2022-12-07T18:14:52.757816Z","shell.execute_reply":"2022-12-07T18:14:52.767855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **First glance in the data:**","metadata":{}},{"cell_type":"code","source":"# To start, let's give a first look at our data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndisplay(train_data.head(10))\n\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ndisplay(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:52.770293Z","iopub.execute_input":"2022-12-07T18:14:52.770993Z","iopub.status.idle":"2022-12-07T18:14:52.819394Z","shell.execute_reply.started":"2022-12-07T18:14:52.770966Z","shell.execute_reply":"2022-12-07T18:14:52.81865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:52.820643Z","iopub.execute_input":"2022-12-07T18:14:52.821491Z","iopub.status.idle":"2022-12-07T18:14:52.834724Z","shell.execute_reply.started":"2022-12-07T18:14:52.821462Z","shell.execute_reply":"2022-12-07T18:14:52.83373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check for missing and duplicate data.\n\ncombined = train_data.append(test_data)\n\nprint(\"NaN values:\")\nprint(combined.isnull().sum())\n\nprint(\"\\n\\nDuplicated Values:\")\nprint(combined.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:52.836577Z","iopub.execute_input":"2022-12-07T18:14:52.837358Z","iopub.status.idle":"2022-12-07T18:14:52.856321Z","shell.execute_reply.started":"2022-12-07T18:14:52.837322Z","shell.execute_reply":"2022-12-07T18:14:52.855215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, most of the \"Cabin\" variable is missing. There's no easy way to fill the empty values, and leaving as it is would result in a biased analysis, so I'll just delete this column.\n\nThe \"Fare\" and \"Embarked\" columns have only 3 missing values together, they can be easily filled.","metadata":{}},{"cell_type":"code","source":"# Deleting the \"Cabin\" column\n\ntrain_data = train_data.drop(columns=\"Cabin\")\n\ntest_data = test_data.drop(columns=\"Cabin\")","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:52.859181Z","iopub.execute_input":"2022-12-07T18:14:52.859776Z","iopub.status.idle":"2022-12-07T18:14:52.867674Z","shell.execute_reply.started":"2022-12-07T18:14:52.859739Z","shell.execute_reply":"2022-12-07T18:14:52.866201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The \"Embarked\" and \"Fare\" columns have the following empty values:\n    \nprint(\"\\n\\nRows with empty 'Embarked' columns:\")\ndisplay(train_data.loc[train_data.Embarked.isnull(), ['PassengerId', 'Name', 'Embarked']])\n\nprint(\"\\n\\nRows with empty 'Fare' columns:\")\ndisplay(test_data.loc[test_data.Fare.isnull(),['PassengerId', 'Name', 'Fare']])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:52.868937Z","iopub.execute_input":"2022-12-07T18:14:52.86922Z","iopub.status.idle":"2022-12-07T18:14:52.893848Z","shell.execute_reply.started":"2022-12-07T18:14:52.869196Z","shell.execute_reply":"2022-12-07T18:14:52.892714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can notice that \"Embarked\" column has only 3 values: 'S', 'C' and Q.\n# Since the most common place someone embarked is in 'S', we'll set that value for the missing values\n\nprint('\\n\\nPort of Embarkation:')\ndisplay(train_data.groupby('Embarked').agg({'Name' : 'count'}))\n\nprint('\\n\\nNew rows:')\ntrain_data.Embarked.fillna(train_data['Embarked'].mode().values[0], inplace = True)\ndisplay(train_data.loc[(train_data.PassengerId == 62) | (train_data.PassengerId == 830), ['PassengerId', 'Name', 'Embarked']])\n\n# I'll set the empty \"Fare\" column with a median value, I don't want to overprice Mr Thomas ticket with a mean value.\nprint(\"\\n\\nMr. Thomas new Fare:\")\ntest_data.loc[test_data[\"PassengerId\"] == 1044, ['Fare']] = round(test_data.Fare.median())\ndisplay(test_data.loc[test_data.PassengerId == 1044, ['PassengerId', 'Name', 'Fare']])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:52.894973Z","iopub.execute_input":"2022-12-07T18:14:52.895765Z","iopub.status.idle":"2022-12-07T18:14:52.92905Z","shell.execute_reply.started":"2022-12-07T18:14:52.895735Z","shell.execute_reply":"2022-12-07T18:14:52.927611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's do a quick correlation matrix to see which variables are more correlated to survival rate\nsns.heatmap(train_data.corr(), annot = True)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:52.932108Z","iopub.execute_input":"2022-12-07T18:14:52.93486Z","iopub.status.idle":"2022-12-07T18:14:53.344909Z","shell.execute_reply.started":"2022-12-07T18:14:52.934811Z","shell.execute_reply":"2022-12-07T18:14:53.344029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Filling Age:**\nOne hard column to fill is \"Age\" column, it does make a big difference, mainly because children have a high correlation to survival (as showed later).\n\nI'll be using a method made by the user [ALLOHVK](https://www.kaggle.com/allohvk) in his [notebook](https://www.kaggle.com/code/allohvk/titanic-missing-age-imputation-tutorial-advanced/notebook). He proposes that is possible to determine someone's age by it's pclass (Ticket Class), Parch (Number of parents) and name (More expecifically the person's title). This process will help find the Age by hand and by using a Neural Network.","metadata":{}},{"cell_type":"code","source":"# First we create the Title column to set all names salutes\ntrain_data['Title'], test_data['Title'] = [df.Name.str.extract('([A-Za-z]+)\\.', expand=False) for df in [train_data, test_data]]\ntrain_data.head()\n\n# We are going also reduct the number of salutations, this is a tip from ALLOHVK to get less noise.\n# This will also help our NN to process the data faster.\nTitleDict = {\"Capt\": \"Officer\",\"Col\": \"Officer\",\"Major\": \"Officer\",\"Jonkheer\": \"Royalty\", \\\n             \"Don\": \"Royalty\", \"Sir\" : \"Royalty\",\"Dr\": \"Royalty\",\"Rev\": \"Royalty\", \\\n             \"Countess\":\"Royalty\", \"Mme\": \"Mrs\", \"Mlle\": \"Miss\", \"Ms\": \"Mrs\",\"Mr\" : \"Mr\", \\\n             \"Mrs\" : \"Mrs\",\"Miss\" : \"Miss\",\"Master\" : \"Master\",\"Lady\" : \"Royalty\"}\n\ntrain_data['Title'], test_data['Title'] = [df.Title.map(TitleDict) for df in [train_data, test_data]]\n\n# Checking if there's a null Title\nprint('\\nNull values in train data:')\ndisplay(train_data.loc[train_data.Title.isnull(), ['Name', 'Title']])\nprint('\\nNull values in test data:')\ndisplay(test_data.loc[test_data.Title.isnull(), ['Name', 'Title']])\n\n# Like in ALLOHVK notebook, there is one null entry, I'll follow his work and set this passenger Title as Royalty\ntest_data.loc[test_data.PassengerId==1306, \"Title\"] = \"Royalty\"\n\nprint('\\nNew Title:')\ndisplay(test_data.loc[test_data.PassengerId==1306, ['Name', 'Title']])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.346239Z","iopub.execute_input":"2022-12-07T18:14:53.347005Z","iopub.status.idle":"2022-12-07T18:14:53.385513Z","shell.execute_reply.started":"2022-12-07T18:14:53.346976Z","shell.execute_reply":"2022-12-07T18:14:53.384322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we can check the passenger average age by Title and pclass.\ncombined = train_data.append(test_data)\ncombined.groupby([\"Title\", \"Pclass\"])[\"Age\"].agg([\"mean\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.386886Z","iopub.execute_input":"2022-12-07T18:14:53.387244Z","iopub.status.idle":"2022-12-07T18:14:53.409575Z","shell.execute_reply.started":"2022-12-07T18:14:53.387208Z","shell.execute_reply":"2022-12-07T18:14:53.407876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is still one important thing to consider while imputing the age: Which female passengers are children or not.\n\nFor a male passenger,the salutation \"Master\" would tell us if he's a children or not, but with women, this becomes a little more complicated.\n\nWe could use the salutation \"Miss\" as a point of start, but what more could be used as a param? Well, a child would not be traveling alone, so if the column \"Parch\" is bigger than 0 there's a higher change of the passenger to be a child.","metadata":{}},{"cell_type":"code","source":"# Setting a new title for female children\nfor df in [train_data, test_data, combined]:\n    df.loc[(df['Title'] == 'Miss') & (df['Parch'] > 0), 'Title'] = 'FemaleChild'\n\ndisplay(combined.loc[(combined.Age.isnull()) & (combined.Title=='FemaleChild'), ['Name', 'Age', 'Title']])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.413255Z","iopub.execute_input":"2022-12-07T18:14:53.41362Z","iopub.status.idle":"2022-12-07T18:14:53.433357Z","shell.execute_reply.started":"2022-12-07T18:14:53.413595Z","shell.execute_reply":"2022-12-07T18:14:53.432345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.435011Z","iopub.execute_input":"2022-12-07T18:14:53.43534Z","iopub.status.idle":"2022-12-07T18:14:53.451352Z","shell.execute_reply.started":"2022-12-07T18:14:53.435295Z","shell.execute_reply":"2022-12-07T18:14:53.449972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that the important variables to determine age are set, I'll start to fill the empty values:\n\n# **Method 1 - Determing age by hand**\n\nIn the same [notebook](https://www.kaggle.com/code/allohvk/titanic-missing-age-imputation-tutorial-advanced/notebook) from [ALLOHVK](https://www.kaggle.com/allohvk), he propose a method to determine age from the mean of the passengers agrouped by their ticket class, sex and title. I'll follow his method.","metadata":{}},{"cell_type":"code","source":"# The ages sets by hand will be kept in a different train and test data frame\ntrain_data_hand = train_data.copy()\ntest_data_hand = test_data.copy()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.452646Z","iopub.execute_input":"2022-12-07T18:14:53.453098Z","iopub.status.idle":"2022-12-07T18:14:53.460278Z","shell.execute_reply.started":"2022-12-07T18:14:53.45307Z","shell.execute_reply":"2022-12-07T18:14:53.459357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This grp variable will contaim the ages to fill the empty values\ngrp = train_data_hand.groupby(['Pclass','Sex','Title'])['Age'].mean().reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n\n# This function will fill the age of a passenger based in its pclass, sex and title.\n# If a passenger is a mister, is in the 1st class and it's male, he'll have the mean value for that group.\n# Now if the passenger is a miss, is in the 2nd class and is female, she'll have the mean for that group.\ndef fill_age(x):\n    return grp[(grp.Pclass==x.Pclass)&(grp.Sex==x.Sex)&(grp.Title==x.Title)]['Age'].values[0]\n\ntrain_data_hand['Age'], test_data_hand['Age'] = [df.apply(lambda x: fill_age(x) if np.isnan(x['Age']) else x['Age'], axis=1) for df in [train_data_hand, test_data_hand]]\n\ncombined = train_data_hand.append(test_data_hand)\ndisplay(combined.groupby(['Pclass','Sex','Title'])['Age'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.461611Z","iopub.execute_input":"2022-12-07T18:14:53.461893Z","iopub.status.idle":"2022-12-07T18:14:53.750674Z","shell.execute_reply.started":"2022-12-07T18:14:53.461868Z","shell.execute_reply":"2022-12-07T18:14:53.749294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we check if there's any other null value.\ndisplay(combined.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.751901Z","iopub.execute_input":"2022-12-07T18:14:53.752145Z","iopub.status.idle":"2022-12-07T18:14:53.766105Z","shell.execute_reply.started":"2022-12-07T18:14:53.752121Z","shell.execute_reply":"2022-12-07T18:14:53.764946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Method 2 - Determining age using neural network**\n\nNow that we have the ages made by hand, we are going to use another method to find the ages using ML.\nThe first thing we should do is pre-processing the data. The \"Survived\" column could help to predict age, but since we are trying to decide the ages from the passengers in train and test data, we are going not to use it, because the test data doesn't have the \"Survived\" column.","metadata":{}},{"cell_type":"code","source":"# But before everything, I'll set the target variable to be found by the model.\ny_ages = train_data[['PassengerId', 'Age']].append(test_data[['PassengerId', 'Age']]).dropna()\n\ntrain_ages = train_data[['PassengerId', 'Age']]\ntest_ages = test_data[['PassengerId', 'Age']]\n\n# I'll also set the target variable for the ML model who will predict the survival change.\ny_survived = train_data['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.811596Z","iopub.execute_input":"2022-12-07T18:14:53.811911Z","iopub.status.idle":"2022-12-07T18:14:53.822967Z","shell.execute_reply.started":"2022-12-07T18:14:53.811882Z","shell.execute_reply":"2022-12-07T18:14:53.822123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here I'll create a function to transform the data into numerical data, I'll also encode some columns.","metadata":{}},{"cell_type":"code","source":"oe = preprocessing.OrdinalEncoder()\ndef process_data(data):\n    #I'll be droping the 'Name' column from the data, I'll not use it.\n    processed_data = data.drop(columns = ['Name', 'Survived'], errors = 'ignore')\n    processed_data = pd.get_dummies(processed_data, columns = ['Pclass', 'Embarked'])\n    processed_data[['Sex', 'Ticket', 'Title']] = oe.fit_transform(data[['Sex', 'Ticket', 'Title']])\n    return processed_data","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.823953Z","iopub.execute_input":"2022-12-07T18:14:53.824331Z","iopub.status.idle":"2022-12-07T18:14:53.833552Z","shell.execute_reply.started":"2022-12-07T18:14:53.824281Z","shell.execute_reply":"2022-12-07T18:14:53.832666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_train_data = process_data(train_data)\n\nprocessed_test_data = process_data(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.834759Z","iopub.execute_input":"2022-12-07T18:14:53.835034Z","iopub.status.idle":"2022-12-07T18:14:53.868497Z","shell.execute_reply.started":"2022-12-07T18:14:53.83501Z","shell.execute_reply":"2022-12-07T18:14:53.867135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here I'm creating a function to standardize the data, so all data will be in the same scale.\n\nI'll have to create two scalers, one to scale the data to the ML model that will predict age, and one that will scale the data with the age already filled to be used with the ML model that I will later create to predict the survival rate.","metadata":{}},{"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\ndef scale_data(data):\n    passenger_column = data.pop('PassengerId')\n    column_names = data.columns\n    scaled_data = scaler.fit_transform(data)   \n    scaled_data = pd.DataFrame(scaled_data, columns = column_names)\n    return scaled_data.assign(PassengerId = passenger_column)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.870164Z","iopub.execute_input":"2022-12-07T18:14:53.870585Z","iopub.status.idle":"2022-12-07T18:14:53.87755Z","shell.execute_reply.started":"2022-12-07T18:14:53.870537Z","shell.execute_reply":"2022-12-07T18:14:53.876035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_train_data = scale_data(processed_train_data.drop(columns = 'Age'))\n\nscaled_test_data = scale_data(processed_test_data.drop(columns = 'Age'))","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.879453Z","iopub.execute_input":"2022-12-07T18:14:53.879907Z","iopub.status.idle":"2022-12-07T18:14:53.899932Z","shell.execute_reply.started":"2022-12-07T18:14:53.879871Z","shell.execute_reply":"2022-12-07T18:14:53.898936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since I'll be creating a supervised NN, I'll be using only the passengers with a age as training data.\ncombined = scaled_train_data.append(scaled_test_data)\n\nX_ages = combined.loc[combined.PassengerId.isin(y_ages.PassengerId)].drop(['PassengerId'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.906627Z","iopub.execute_input":"2022-12-07T18:14:53.906862Z","iopub.status.idle":"2022-12-07T18:14:53.919032Z","shell.execute_reply.started":"2022-12-07T18:14:53.906832Z","shell.execute_reply":"2022-12-07T18:14:53.918324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Separating the train data and test data to use in the neural network\nX_train, X_test, y_train, y_test = train_test_split(X_ages, y_ages.drop(columns = 'PassengerId'), \n                                                    test_size=0.3, random_state=123)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.920692Z","iopub.execute_input":"2022-12-07T18:14:53.92225Z","iopub.status.idle":"2022-12-07T18:14:53.931589Z","shell.execute_reply.started":"2022-12-07T18:14:53.922198Z","shell.execute_reply":"2022-12-07T18:14:53.929861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history):\n    hist = pd.DataFrame(history.history)\n    hist['epoch'] = history.epoch\n\n    plt.figure()\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Abs Error [MPG]')\n    plt.plot(hist['epoch'], hist['mae'], label='Train Error')\n    plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error')\n    plt.legend()\n\n    plt.figure()\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Square Error [$MPG^2$]')\n    plt.plot(hist['epoch'], hist['mse'], label='Train Error')\n    plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.933077Z","iopub.execute_input":"2022-12-07T18:14:53.933438Z","iopub.status.idle":"2022-12-07T18:14:53.942003Z","shell.execute_reply.started":"2022-12-07T18:14:53.933411Z","shell.execute_reply":"2022-12-07T18:14:53.940532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating the model\nfrom tensorflow.keras import regularizers\nkr = regularizers.l1_l2(l1 = 1e-3, l2 = 1e-3)\n\nmodel = keras.Sequential([\n    layers.Dense(128,activation='relu',input_shape=[len(X_train.keys())], kernel_regularizer = kr),\n    layers.Dropout(0.5),\n    layers.Dense(64,activation='relu', kernel_regularizer = kr),\n    layers.Dropout(0.5),\n    layers.Dense(1)\n])\n\nmodel.compile(optimizer = 'RMSprop', loss = 'mse', metrics = ['mae', 'mse'])","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.943983Z","iopub.execute_input":"2022-12-07T18:14:53.94444Z","iopub.status.idle":"2022-12-07T18:14:53.990245Z","shell.execute_reply.started":"2022-12-07T18:14:53.944404Z","shell.execute_reply":"2022-12-07T18:14:53.989283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, batch_size = 64, epochs = 2500,validation_split = 0.3,\n                    verbose = 0)\nplot_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:14:53.992378Z","iopub.execute_input":"2022-12-07T18:14:53.992742Z","iopub.status.idle":"2022-12-07T18:16:58.446218Z","shell.execute_reply.started":"2022-12-07T18:14:53.992716Z","shell.execute_reply":"2022-12-07T18:16:58.444369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's check how this model deals with the test data.\nmodel.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:16:58.449213Z","iopub.execute_input":"2022-12-07T18:16:58.449522Z","iopub.status.idle":"2022-12-07T18:16:58.534149Z","shell.execute_reply.started":"2022-12-07T18:16:58.449496Z","shell.execute_reply":"2022-12-07T18:16:58.533151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As seen by the Mean Absolute error, the model presents a error of approximately 8 years for more or less, which I consider a good result.","metadata":{}},{"cell_type":"code","source":"#This function will set the ages in the train and test data with the help from the model I created.\ndef input_age(data):\n    nan_age = data.loc[data.Age.isnull()].drop(['Age'], axis = 1)\n    missing_age = model.predict(\n        nan_age.drop(columns = ['PassengerId', 'Survived'], errors = 'ignore'))\n    data.loc[data.Age.isnull(), ['Age']] = missing_age\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:16:58.539795Z","iopub.execute_input":"2022-12-07T18:16:58.540108Z","iopub.status.idle":"2022-12-07T18:16:58.545736Z","shell.execute_reply.started":"2022-12-07T18:16:58.540077Z","shell.execute_reply":"2022-12-07T18:16:58.544831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_ml = input_age(scaled_train_data.assign(Age = train_ages['Age']))\n#display(train_data_ml)\n\ntest_data_ml = input_age(scaled_test_data.assign(Age = test_ages['Age']))\n#display(test_data_ml)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:16:58.547051Z","iopub.execute_input":"2022-12-07T18:16:58.547586Z","iopub.status.idle":"2022-12-07T18:16:58.706206Z","shell.execute_reply.started":"2022-12-07T18:16:58.547554Z","shell.execute_reply":"2022-12-07T18:16:58.704396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As show below, we have a pretty decent result, showing little difference between the ages set by hand. ","metadata":{}},{"cell_type":"code","source":"full_data = train_data.append(test_data)\nfull_data_ml = train_data_ml.append(test_data_ml)\nfull_data.loc[full_data.PassengerId == full_data_ml.PassengerId, ['Age']] = full_data_ml.Age\n\nprint('\\nAge set by ML:')\ndisplay(full_data.groupby(['Pclass','Sex','Title'])['Age'].mean())\n\nprint('\\n\\nAge set by hand:')\ndisplay(train_data_hand.append(test_data_hand).groupby(['Pclass','Sex','Title'])['Age'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:16:58.708617Z","iopub.execute_input":"2022-12-07T18:16:58.709048Z","iopub.status.idle":"2022-12-07T18:16:58.741587Z","shell.execute_reply.started":"2022-12-07T18:16:58.70901Z","shell.execute_reply":"2022-12-07T18:16:58.740241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predicting survival rate**\n\nNow that we have all data we need, I'm gonna create another a classification NN to predict if a passenger will survive. There is still some pre processing we should do before letting the NN model. One important thing I should is binning the ages.","metadata":{}},{"cell_type":"markdown","source":"This will be the model who will predict if the passenger will survive.","metadata":{}},{"cell_type":"code","source":"#This is the model created to predict survival rate, it could have less neurons, but this will do.\ndef create_model(X, y, model_name):\n    model = keras.Sequential([\n        layers.Dense(32, activation='tanh', input_shape=[len(X.keys())]),\n        layers.Dropout(0.5),\n        layers.Dense(32, activation='tanh'),\n        layers.Dropout(0.5),\n        layers.Dense(32, activation='tanh'),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')], name = model_name)\n    \n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n    \n    history = model.fit(X, y, batch_size = 128, epochs = 600,validation_split = 0.3, verbose = 0)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:24:36.150648Z","iopub.execute_input":"2022-12-07T18:24:36.150995Z","iopub.status.idle":"2022-12-07T18:24:36.159157Z","shell.execute_reply.started":"2022-12-07T18:24:36.150961Z","shell.execute_reply":"2022-12-07T18:24:36.157769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is an auxiliar function that will bring some graphs and measures to evaluate the model we'll construct\ndef display_acc_hist(history):\n    history_df = pd.DataFrame(history.history)\n    # Start the plot at epoch 0\n    history_df.loc[0:, ['loss', 'val_loss']].plot()\n    history_df.loc[0:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n\n    print((\"Best Validation Loss: {:0.4f}\" +\\\n           \"\\nBest Validation Accuracy: {:0.4f}\")\\\n           .format(history_df['val_loss'].min(),\n           history_df['val_binary_accuracy'].max()))\n    return\n\n#And this function will give some important measures\ndef print_results(y_test, y_pred):\n    print('\\nConfusion Matrix: \\n' , confusion_matrix(y_test, y_pred))\n    print('\\n', classification_report(y_test, y_pred))\n    print('\\nAccuracy: ' , accuracy_score(y_test, y_pred))\n    return accuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:16:58.762291Z","iopub.execute_input":"2022-12-07T18:16:58.762674Z","iopub.status.idle":"2022-12-07T18:16:58.771625Z","shell.execute_reply.started":"2022-12-07T18:16:58.762644Z","shell.execute_reply":"2022-12-07T18:16:58.770249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We still have some pre-processing to do before training the new model, we need to scale the Ages created by ML and all the data where we set the Age by hand. Fortunally, we already have the functions to do so.","metadata":{}},{"cell_type":"code","source":"#This function will send the data to scale, and also is gonna to binnarize the ages in groups\ndef last_processing(data, ages):\n    data.loc[data.PassengerId == ages.PassengerId, ['Age']] = ages.Age\n    age_interval = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    data['Age'] = pd.cut(data['Age'].astype(int), bins = 10, labels = age_interval)\n    data = pd.get_dummies(data, columns = ['Age'])\n    return scale_data(data).drop(columns = 'PassengerId')","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:16:58.772818Z","iopub.execute_input":"2022-12-07T18:16:58.77319Z","iopub.status.idle":"2022-12-07T18:16:58.786553Z","shell.execute_reply.started":"2022-12-07T18:16:58.773128Z","shell.execute_reply":"2022-12-07T18:16:58.785282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_ml = last_processing(processed_train_data.copy(), train_data_ml)\n\ntest_data_ml = last_processing(processed_test_data.copy(), test_data_ml)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:16:58.78759Z","iopub.execute_input":"2022-12-07T18:16:58.787863Z","iopub.status.idle":"2022-12-07T18:16:58.821792Z","shell.execute_reply.started":"2022-12-07T18:16:58.787838Z","shell.execute_reply":"2022-12-07T18:16:58.820823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_ml, y_survived, test_size=0.3, random_state=123)\nmodel_ml, history = create_model(X_train, y_train, 'ages_filled_by_NN.')\ndisplay_acc_hist(history)\n\ny_pred = model_ml.predict(X_test) > 0.5\n\naccuracy_ml = print_results(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:24:43.017254Z","iopub.execute_input":"2022-12-07T18:24:43.017623Z","iopub.status.idle":"2022-12-07T18:25:07.745205Z","shell.execute_reply.started":"2022-12-07T18:24:43.017597Z","shell.execute_reply":"2022-12-07T18:25:07.743966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_hand = last_processing(processed_train_data.copy(), train_data_hand)\n\ntest_data_hand = last_processing(processed_test_data.copy(), test_data_hand)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:17:24.977585Z","iopub.execute_input":"2022-12-07T18:17:24.978376Z","iopub.status.idle":"2022-12-07T18:17:25.008041Z","shell.execute_reply.started":"2022-12-07T18:17:24.978332Z","shell.execute_reply":"2022-12-07T18:17:25.006745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_hand, y_survived, test_size=0.3, random_state=123)\nmodel_hand, history = create_model(X_train, y_train, 'ages_filled_by_hand.')\ndisplay_acc_hist(history)\n\ny_pred = np.around(model_hand.predict(X_test))\n\naccuracy_hand = print_results(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:25:25.826828Z","iopub.execute_input":"2022-12-07T18:25:25.827196Z","iopub.status.idle":"2022-12-07T18:25:50.799973Z","shell.execute_reply.started":"2022-12-07T18:25:25.827165Z","shell.execute_reply":"2022-12-07T18:25:50.79836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Results:**\nBy the end, there is no big difference between the data filled with the ages filled by hand and filled using NN, so I'll just use the model that has the biggest accuracy score. ","metadata":{}},{"cell_type":"code","source":"if accuracy_ml > accuracy_hand:\n    best_model = model_ml\nelse:\n    best_model = model_hand\n\nsurvived = np.around(best_model.predict(test_data_hand))\n\noutput = test_data['PassengerId'].to_frame().assign(Survived = survived)\noutput['Survived'] = output['Survived'].astype(int)\n\nprint('\\nThis result was achieved using the model with the ' + best_model._name)\ndisplay(output.head())\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-12-07T18:18:04.837676Z","iopub.execute_input":"2022-12-07T18:18:04.838096Z","iopub.status.idle":"2022-12-07T18:18:04.926417Z","shell.execute_reply.started":"2022-12-07T18:18:04.838057Z","shell.execute_reply":"2022-12-07T18:18:04.925375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}